import errno
import os
import sys

import numpy as np
import requests
import torch
from hsh.library.hash import Hasher
from torchvision import transforms
from tqdm import tqdm

from . import data_loader, u2net


def download_file_from_google_drive(id, fname, destination):
    """
    Download files from given Google Drive URL

    :param id: the ID for Google Drive file, typically shown in its URL
    :param fname: the name of the file
    :param destination: the path to store the file
    """
    print("Downloading "+ fname)

    head, tail = os.path.split(destination)
    os.makedirs(head, exist_ok=True)

    URL = "https://docs.google.com/uc?export=download"

    session = requests.Session()
    response = session.get(URL, params={"id": id}, stream=True)

    token = None
    for key, value in response.cookies.items():
        if key.startswith("download_warning"):
            token = value
            break

    if token:
        params = {"id": id, "confirm": token}
        response = session.get(URL, params=params, stream=True)

    total = int(response.headers.get("content-length", 0))

    with open(destination, "wb") as file, tqdm(
        desc=f"Downloading {tail} to {head}",
        total=total,
        unit="iB",
        unit_scale=True,
        unit_divisor=1024,
    ) as bar:
        for data in response.iter_content(chunk_size=1024):
            size = file.write(data)
            bar.update(size)


def load_model(model_name: str = None):
    '''
    Load specific models, download them from given links if needed.

    :params model_name: the name of the model. Only u2net, u2netp, u2net_seg and u2net_portrait is supported
    :return: pretrained u2net model
    '''
    if model_name is None:
        model_name = 'u2net'
    hasher = Hasher()

    if not os.path.exists(os.path.join("model")):
        os.mkdir("model")

    path = os.environ.get(
        "U2NET_PATH",
        os.path.expanduser(os.path.join("model", model_name + ".pth")),
    )

    if model_name == "u2netp":
        net = u2net.U2NETP(3, 1)
        if (
            not os.path.exists(path)
            or hasher.md5(path) != "e4f636406ca4e2af789941e7f139ee2e"
        ):
            download_file_from_google_drive(
                "1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy",
                "u2netp.pth",
                path,
            )

    elif model_name == "u2net":
        net = u2net.U2NET(3, 1)
        if (
            not os.path.exists(path)
            or hasher.md5(path) != "347c3d51b01528e5c6c071e3cff1cb55"
        ):
            download_file_from_google_drive(
                "1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ",
                "u2net.pth",
                path,
            )

    elif model_name == "u2net_human_seg":
        net = u2net.U2NET(3, 1)
        if (
            not os.path.exists(path)
            or hasher.md5(path) != "09fb4e49b7f785c9f855baf94916840a"
        ):
            download_file_from_google_drive(
                "1-Yg0cxgrNhHP-016FPdp902BR-kSsA4P",
                "u2net_human_seg.pth",
                path,
            )
    elif model_name == "u2net_portrait":
        net = u2net.U2NET(3, 1)
        if (
            not os.path.exists(path)
            or hasher.md5(path) != 'c7cff57409664b679dc7a5a445b259e4'
        ):
            download_file_from_google_drive(
                "1IG3HdpcRiDoWNookbncQjeaPN28t90yW",
                "u2net_portrait.pth",
                path,
            )
    else:
        print("Choose between u2net, u2net_human_seg, u2netp or u2net_portrait", file=sys.stderr)
    try:
        if torch.cuda.is_available():
            net.load_state_dict(torch.load(path))
            net.to(torch.device("cuda"))
        else:
            net.load_state_dict(
                torch.load(
                    path,
                    map_location="cpu",
                )
            )
    except FileNotFoundError:
        raise FileNotFoundError(
            errno.ENOENT, os.strerror(errno.ENOENT), model_name + ".pth"
        )

    net.eval()

    return net


def norm_pred(d):
    """
    Normalize the prediction result

    :param d: the input image
    :return: normalized image
    """
    ma = torch.max(d)
    mi = torch.min(d)
    dn = (d - mi) / (ma - mi)

    return dn


def preprocess(image):
    """
    Pre-process and wrap-up the data for the model to predict

    :param image: the input image
    :result: data block generated by torchvision.transform, including label infos
    """
    label_3 = np.zeros(image.shape)
    label = np.zeros(label_3.shape[0:2])

    if 3 == len(label_3.shape):
        label = label_3[:, :, 0]
    elif 2 == len(label_3.shape):
        label = label_3

    if 3 == len(image.shape) and 2 == len(label.shape):
        label = label[:, :, np.newaxis]
    elif 2 == len(image.shape) and 2 == len(label.shape):
        image = image[:, :, np.newaxis]
        label = label[:, :, np.newaxis]

    transform = transforms.Compose(
        [data_loader.RescaleT(320), data_loader.ToTensorLab(flag=0)]
    )
    sample = transform({"imidx": np.array([0]), "image": image, "label": label})

    return sample


def predict(net, item, portrait=False):
    """
    Predicting the result with loaded u2net model

    :param net: the model used for prediction
    :param item: input image, in NumPy array
    :param portrait: indicating whether is portrait generation or not
    :return: a NumPy array storing the generated image
    """
    sample = preprocess(item)

    with torch.no_grad():
        # Move data to CUDA if available
        if torch.cuda.is_available():
            inputs_test = torch.cuda.FloatTensor(
                sample["image"].unsqueeze(0).cuda().float()
            )
        else:
            inputs_test = torch.FloatTensor(sample["image"].unsqueeze(0).float())

        # Predict
        d1, d2, d3, d4, d5, d6, d7 = net(inputs_test)

        # If the result is used for portrait generation, use its opposite image
        if portrait:
            pred = 1.0 - d1[:, 0, :, :]
        else:
            pred = d1[:, 0, :, :]

        # Post-process
        result = norm_pred(pred)
        result = result.squeeze()
        predict_np = result.cpu().detach().numpy()

        del d1, d2, d3, d4, d5, d6, d7, pred, result, inputs_test, sample

        return predict_np
